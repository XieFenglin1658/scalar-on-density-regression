---
title: "simulation_code_11_20"
author: "Fenglin Xie"
date: "2025-11-21"
output: github_document
---
```{r}
# Simulation Study: Impact of Sample Size on Density Estimation and Weight Function Recovery
# Framework: Measurement Error Model - Sample size increases -> Density estimation improves -> Weight function estimation improves

library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(splines)
library(matrixStats)

# ==================== PARAMETER SETTINGS ====================

# Population parameters: All individual true densities center around these
alpha0 <- 2    # Central alpha parameter for Beta distribution
beta0 <- 5     # Central beta parameter for Beta distribution
sigma_alpha <- 0.2  # Between-individual variation in alpha (small to ensure similar shapes)
sigma_beta <- 0.5   # Between-individual variation in beta

# True weight function
true_weight_function <- function(t) {
  # Define a realistic weight function, e.g., higher weights in central regions
  0.5 + 2 * (t - 0.5)^2
}

# Sample size sequence (from small to large)
sample_sizes <- c(10, 20, 50, 100, 200, 500, 1000)

# Number of simulation replicates
n_replicates <- 200

# Number of individuals
n_individuals <- 100

# Error term standard deviation
sigma_error <- 0.1

# Number of basis functions for weight function estimation
n_basis <- 5

# ==================== HELPER FUNCTIONS ====================

#' Generate true individual density parameters
#' @param n Number of individuals
#' @return Dataframe with true alpha and beta parameters for each individual
generate_true_parameters <- function(n) {
  data.frame(
    individual_id = 1:n,
    alpha_true = pmax(0.1, rnorm(n, alpha0, sigma_alpha)),
    beta_true = pmax(0.1, rnorm(n, beta0, sigma_beta))
  )
}

#' Generate observations from Beta distribution
#' @param alpha Shape parameter alpha
#' @param beta Shape parameter beta  
#' @param sample_size Number of observations to generate
#' @return Vector of observations
generate_observations <- function(alpha, beta, sample_size) {
  rbeta(sample_size, alpha, beta)
}

#' Estimate Beta distribution parameters using method of moments
#' @param observations Vector of observations
#' @return List with estimated alpha and beta parameters
estimate_beta_parameters <- function(observations) {
  if (length(observations) < 2) {
    return(list(alpha_hat = alpha0, beta_hat = beta0))
  }
  
  m1 <- mean(observations)
  m2 <- mean(observations^2)
  
  if (m2 <= m1^2 || m1 <= 0 || m1 >= 1) {
    return(list(alpha_hat = alpha0, beta_hat = beta0))
  }
  
  variance <- m2 - m1^2
  alpha_hat <- m1 * (m1 * (1 - m1) / variance - 1)
  beta_hat <- (1 - m1) * (m1 * (1 - m1) / variance - 1)
  
  # Ensure positive parameters
  list(
    alpha_hat = max(0.1, alpha_hat),
    beta_hat = max(0.1, beta_hat)
  )
}

#' Compute mean of Beta distribution
#' @param alpha Shape parameter alpha
#' @param beta Shape parameter beta
#' @return Mean of Beta(alpha, beta)
beta_distribution_mean <- function(alpha, beta) {
  alpha / (alpha + beta)
}

#' Compute integral of weight function with respect to Beta density
#' @param alpha Shape parameter alpha
#' @param beta Shape parameter beta
#' @param weight_func Weight function
#' @return Numerical integral value
compute_weight_integral <- function(alpha, beta, weight_func) {
  # Numerical integration: ∫ weight_func(t) * Beta(t; alpha, beta) dt
  t_grid <- seq(0.001, 0.999, length.out = 1000)
  integrand <- weight_func(t_grid) * dbeta(t_grid, alpha, beta)
  sum(integrand) * (t_grid[2] - t_grid[1])
}

#' Estimate weight function using basis expansion
#' @param estimated_densities Dataframe with estimated density parameters
#' @param Y Response vector
#' @param n_basis Number of basis functions
#' @return Estimated weight function
estimate_weight_function <- function(estimated_densities, Y, n_basis) {
  # Create B-spline basis functions
  t_grid <- seq(0, 1, length.out = 100)
  basis_functions <- bs(t_grid, df = n_basis, degree = 3, intercept = TRUE)
  
  # Compute design matrix X
  X_matrix <- matrix(0, nrow = length(Y), ncol = n_basis)
  
  for (i in 1:length(Y)) {
    alpha_hat <- estimated_densities$alpha_hat[i]
    beta_hat <- estimated_densities$beta_hat[i]
    
    for (j in 1:n_basis) {
      # Compute ∫ B_j(t) * f_i_hat(t) dt
      integrand <- basis_functions[, j] * dbeta(t_grid, alpha_hat, beta_hat)
      X_matrix[i, j] <- sum(integrand) * (t_grid[2] - t_grid[1])
    }
  }
  
  # Fit linear model (with intercept)
  X_design <- cbind(1, X_matrix)  # Add intercept column
  coefficients <- solve(t(X_design) %*% X_design, t(X_design) %*% Y)
  
  # Reconstruct weight function estimate
  estimated_weight_function <- function(t) {
    basis_t <- predict(basis_functions, t)
    coefficients[1] + as.numeric(basis_t %*% coefficients[-1])
  }
  
  return(estimated_weight_function)
}

#' Compute L2 distance between two functions
#' @param func1 First function
#' @param func2 Second function  
#' @param grid_points Number of grid points for numerical integration
#' @return L2 distance
compute_l2_distance <- function(func1, func2, grid_points = 100) {
  t_values <- seq(0, 1, length.out = grid_points)
  differences <- func1(t_values) - func2(t_values)
  sqrt(mean(differences^2))
}

# ==================== MAIN SIMULATION FUNCTION ====================

run_simulation_replicate <- function(sample_size, n_replicates) {
  cat("Processing sample size:", sample_size, "\n")
  
  results <- list()
  
  for (replicate in 1:n_replicates) {
    # 1. Generate true individual parameters
    true_parameters <- generate_true_parameters(n_individuals)
    
    # 2. Generate response variable (based on true densities)
    true_parameters <- true_parameters %>%
      mutate(
        integral_term = map2_dbl(alpha_true, beta_true, ~ compute_weight_integral(.x, .y, true_weight_function)),
        Y = integral_term + rnorm(n(), 0, sigma_error)
      )
    
    # 3. Generate observations and estimate density functions
    estimated_densities <- true_parameters %>%
      mutate(
        observations = map2(alpha_true, beta_true, ~ generate_observations(.x, .y, sample_size)),
        param_estimates = map(observations, estimate_beta_parameters),
        alpha_hat = map_dbl(param_estimates, "alpha_hat"),
        beta_hat = map_dbl(param_estimates, "beta_hat")
      )
    
    # 4. Estimate weight function
    estimated_weight_func <- estimate_weight_function(estimated_densities, estimated_densities$Y, n_basis)
    
    # 5. Compute estimation errors
    density_estimation_error <- with(estimated_densities, {
      mean(sqrt((alpha_hat - alpha_true)^2 + (beta_hat - beta_true)^2))
    })
    
    weight_estimation_error <- compute_l2_distance(estimated_weight_func, true_weight_function)
    
    # Store results
    results[[replicate]] <- list(
      sample_size = sample_size,
      replicate = replicate,
      estimated_weight_function = estimated_weight_func,
      density_error = density_estimation_error,
      weight_error = weight_estimation_error
    )
  }
  
  return(results)
}

# ==================== EXECUTE SIMULATION ====================

cat("Starting simulation...\n")
simulation_results <- list()

for (sample_size in sample_sizes) {
  results <- run_simulation_replicate(sample_size, n_replicates)
  simulation_results <- c(simulation_results, results)
}

# ==================== RESULTS PROCESSING ====================

# Extract error metrics
error_metrics <- map_df(simulation_results, ~ {
  data.frame(
    sample_size = .x$sample_size,
    density_error = .x$density_error,
    weight_error = .x$weight_error
  )
})

# Compute weight function estimates on grid
t_grid <- seq(0, 1, length.out = 50)
weight_estimates <- map_df(simulation_results, ~ {
  estimates <- .x$estimated_weight_function(t_grid)
  data.frame(
    sample_size = .x$sample_size,
    replicate = .x$replicate,
    t = t_grid,
    beta_hat = estimates
  )
})

# ==================== VISUALIZATION ====================

# 1. Density estimation error vs sample size
p1 <- ggplot(error_metrics, aes(x = factor(sample_size), y = density_error)) +
  geom_boxplot(aes(fill = factor(sample_size)), alpha = 0.7) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 3, color = "red") +
  labs(
    title = "Density Estimation Error vs Sample Size",
    subtitle = "Increasing sample size improves density estimation accuracy",
    x = "Sample Size",
    y = "Density Parameter Estimation Error"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# 2. Weight function estimation error vs sample size
p2 <- ggplot(error_metrics, aes(x = factor(sample_size), y = weight_error)) +
  geom_boxplot(aes(fill = factor(sample_size)), alpha = 0.7) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 3, color = "red") +
  labs(
    title = "Weight Function Estimation Error vs Sample Size",
    subtitle = "Improved density estimation leads to improved weight function estimation",
    x = "Sample Size",
    y = "Weight Function L2 Error"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# 3. Relationship between density error and weight error
p3 <- ggplot(error_metrics, aes(x = density_error, y = weight_error)) +
  geom_point(alpha = 0.5, aes(color = factor(sample_size))) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  labs(
    title = "Relationship Between Density Estimation Error and Weight Function Error",
    x = "Density Parameter Estimation Error",
    y = "Weight Function Estimation Error",
    color = "Sample Size"
  ) +
  theme_minimal()

# 4. Evolution of weight function estimates
weight_summary <- weight_estimates %>%
  group_by(sample_size, t) %>%
  summarise(
    beta_hat_mean = mean(beta_hat),
    beta_hat_sd = sd(beta_hat),
    .groups = 'drop'
  ) %>%
  mutate(
    beta_true = true_weight_function(t)
  )

p4 <- ggplot(weight_summary, aes(x = t)) +
  geom_ribbon(aes(ymin = beta_hat_mean - beta_hat_sd, 
                  ymax = beta_hat_mean + beta_hat_sd, 
                  fill = factor(sample_size)), 
              alpha = 0.2) +
  geom_line(aes(y = beta_hat_mean, color = factor(sample_size)), size = 1) +
  geom_line(aes(y = beta_true), color = "black", linetype = "dashed", size = 1.5) +
  labs(
    title = "Evolution of Weight Function Estimates with Sample Size",
    subtitle = "Solid lines: estimated means, Shaded: ±1 standard deviation, Dashed: true function",
    x = "t",
    y = "β(t)",
    color = "Sample Size",
    fill = "Sample Size"
  ) +
  theme_minimal()

# 5. Convergence rate analysis
convergence_data <- error_metrics %>%
  group_by(sample_size) %>%
  summarise(
    mean_density_error = mean(density_error),
    mean_weight_error = mean(weight_error),
    .groups = 'drop'
  )

p5 <- ggplot(convergence_data, aes(x = sample_size)) +
  geom_point(aes(y = mean_density_error, color = "Density Estimation Error"), size = 3) +
  geom_point(aes(y = mean_weight_error, color = "Weight Function Error"), size = 3) +
  geom_line(aes(y = mean_density_error, color = "Density Estimation Error"), size = 1) +
  geom_line(aes(y = mean_weight_error, color = "Weight Function Error"), size = 1) +
  scale_x_log10() +
  scale_y_log10() +
  labs(
    title = "Error Convergence Rates (Log-Log Scale)",
    x = "Sample Size (log scale)",
    y = "Mean Error (log scale)",
    color = "Error Type"
  ) +
  theme_minimal()

# ==================== DISPLAY RESULTS ====================

cat("Simulation completed! Displaying results...\n")

print(p1)
print(p2)
print(p3)
print(p4)
print(p5)

# ==================== STATISTICAL SUMMARY ====================

cat("\n=== STATISTICAL SUMMARY ===\n")
summary_statistics <- error_metrics %>%
  group_by(sample_size) %>%
  summarise(
    density_error_mean = mean(density_error),
    density_error_sd = sd(density_error),
    weight_error_mean = mean(weight_error),
    weight_error_sd = sd(weight_error),
    .groups = 'drop'
  )

print(summary_statistics)

# Fit convergence rate models
convergence_model_density <- lm(log(mean_density_error) ~ log(sample_size), 
                               data = convergence_data)
convergence_model_weight <- lm(log(mean_weight_error) ~ log(sample_size), 
                              data = convergence_data)

cat("\n=== CONVERGENCE RATE ANALYSIS ===\n")
cat(sprintf("Density estimation error convergence rate: %.3f (theoretical expectation: -0.5)\n", 
            -coef(convergence_model_density)[2]))
cat(sprintf("Weight function error convergence rate: %.3f (theoretical expectation: -0.5)\n", 
            -coef(convergence_model_weight)[2]))

# ==================== SAVE RESULTS ====================

# Save main results
write.csv(error_metrics, "simulation_error_metrics.csv", row.names = FALSE)
write.csv(weight_summary, "weight_function_estimates.csv", row.names = FALSE)

cat("\nResults saved to:\n")
cat("- simulation_error_metrics.csv: Error metrics data\n")
cat("- weight_function_estimates.csv: Weight function estimates\n")

cat("\n=== KEY FINDINGS ===\n")
cat("1. Increasing sample size significantly improves density function estimation accuracy\n")
cat("2. Improved density estimation directly leads to improved weight function estimation\n")
cat("3. Error convergence rates are close to theoretical expectation (1/√n)\n")
cat("4. Estimates show high variance with small samples but stabilize with large samples\n")
```

